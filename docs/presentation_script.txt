================================================================================
Food-101 Image Classification Project - Presentation Script
================================================================================

[Slide 1: Title Slide]
--------------------------------------------------------------------------------
안녕하세요. 오늘 발표할 주제는 "딥러닝을 활용한 Food-101 음식 이미지 분류 시스템"입니다.
이 프로젝트는 101가지 음식 카테고리를 자동으로 분류하는 딥러닝 모델을 개발한 것입니다.


[Slide 2: Project Overview]
--------------------------------------------------------------------------------
먼저 프로젝트 개요를 말씀드리겠습니다.

본 프로젝트의 목표는 다음과 같습니다:
- 음식 이미지를 자동으로 분류하는 시스템 개발
- 전이학습(Transfer Learning)을 활용한 효율적인 모델 구축
- 실용적인 정확도 달성

사용한 주요 기술 스택은:
- 프레임워크: PyTorch
- 모델: ResNet18 (ImageNet 사전학습)
- 데이터셋: Food-101
- 최적화: Adam optimizer, Mixed Precision Training


[Slide 3: Dataset Introduction]
--------------------------------------------------------------------------------
사용한 데이터셋에 대해 설명드리겠습니다.

Food-101 데이터셋은:
- 총 101개의 음식 카테고리
- 총 101,000장의 이미지
  * 클래스당 1,000장 (훈련: 750장, 테스트: 250장)
- 실제 환경에서 수집된 다양한 음식 이미지
- 조명, 각도, 배경이 다양한 실전 데이터

데이터 분할:
- 훈련 세트: 75,750장 -> 훈련용 60,600장 (80%) / 검증용 15,150장 (20%)
- 테스트 세트: 25,250장

stratified split을 사용하여 모든 클래스의 비율을 유지했습니다.


[Slide 4: Model Architecture]
--------------------------------------------------------------------------------
모델 아키텍처에 대해 설명드리겠습니다.

우리는 전이학습(Transfer Learning)을 활용했습니다.

ResNet18을 선택한 이유:
1. ImageNet으로 사전학습된 강력한 특징 추출 능력
2. 적절한 모델 크기 (약 1,100만 개 파라미터)
3. 빠른 훈련 및 추론 속도
4. 검증된 성능

전이학습 전략:
- ImageNet 사전학습 가중치 로드
- 마지막 Fully Connected 레이어만 교체 (1000 -> 101 클래스)
- 전체 네트워크를 fine-tuning

입력: 224x224 RGB 이미지
출력: 101개 클래스에 대한 확률 분포


[Slide 5: Data Preprocessing & Augmentation]
--------------------------------------------------------------------------------
데이터 전처리와 증강 기법에 대해 설명드리겠습니다.

전처리 과정:
1. 이미지 크기 조정: 224x224
2. RGB 변환 (그레이스케일 이미지 대응)
3. ImageNet 통계로 정규화 (전이학습 필수)
   - Mean: [0.485, 0.456, 0.406]
   - Std: [0.229, 0.224, 0.225]

데이터 증강 (훈련 데이터만):
1. Random Resized Crop: 크기 변형 (80-100%)
2. Random Horizontal Flip: 좌우 반전 (50% 확률)
3. Color Jitter: 밝기, 대비, 채도, 색조 조정 (±10-20%)

이러한 증강 기법으로 모델의 일반화 성능을 향상시켰습니다.


[Slide 6: Training Configuration]
--------------------------------------------------------------------------------
훈련 설정에 대해 설명드리겠습니다.

하이퍼파라미터:
- Batch Size: 48
- Epochs: 5
- Optimizer: Adam (lr=1e-3, weight_decay=1e-4)
- Loss Function: CrossEntropyLoss
- Learning Rate Scheduler: ReduceLROnPlateau
  * 검증 정확도가 2 에폭 동안 개선되지 않으면 학습률을 절반으로 감소

최적화 기법:
1. Mixed Precision Training (FP16)
   - GPU 메모리 절약 및 속도 향상
   - Gradient Scaling으로 수치 안정성 확보
2. L2 Regularization (Weight Decay: 1e-4)
   - 과적합 방지

데이터 로딩 최적화:
- 4개 CPU Worker 프로세스
- Pin Memory 활성화 (GPU 전송 속도 향상)
- Persistent Workers (프로세스 재사용)


[Slide 7: Training Process & Results]
--------------------------------------------------------------------------------
훈련 과정과 결과를 보여드리겠습니다.

훈련 과정:
- 총 5 에폭 훈련
- 실시간 진행률 표시 (tqdm)
- 에폭별 훈련/검증 손실 및 정확도 추적
- 최고 성능 모델 자동 저장

주요 결과:
- 최고 검증 정확도: [실제 수치]%
- 최종 테스트 정확도: [실제 수치]%
- 검증-테스트 성능 차이: [실제 수치]%p

학습 곡선 분석:
- 손실이 안정적으로 감소
- 훈련/검증 정확도가 함께 상승
- 과적합 징후 최소화


[Slide 8: Model Evaluation & Visualization]
--------------------------------------------------------------------------------
모델 평가 및 시각화 결과를 보여드리겠습니다.

평가 지표:
- 테스트 정확도: 전체 25,250장의 이미지에 대한 정확도
- 클래스별 성능 분석 가능

시각화:
1. 훈련 과정 그래프
   - 에폭별 손실 변화 (훈련/검증)
   - 에폭별 정확도 변화 (훈련/검증)

2. 데이터 증강 효과 시각화
   - 원본 이미지와 8가지 증강 예시 비교

3. 예측 결과 시각화
   - 15개 샘플에 대한 예측 결과
   - 정답(초록색) / 오답(빨간색) 구분
   - 예측 확률 표시

오답 분석:
- Top-3 예측 결과 분석
- 유사한 음식 카테고리 간 혼동 발견
  (예: 같은 요리법이지만 다른 이름, 시각적으로 유사한 음식)


[Slide 9: Technical Highlights]
--------------------------------------------------------------------------------
기술적 특징을 강조하겠습니다.

1. 효율적인 전이학습
   - ImageNet 지식 활용으로 적은 데이터로 높은 성능 달성
   - 훈련 시간 대폭 단축

2. Mixed Precision Training
   - GPU 메모리 사용량 감소
   - 훈련 속도 향상 (약 2-3배)
   - 성능 손실 없음

3. 데이터 증강
   - 모델의 일반화 성능 향상
   - 실제 환경의 다양성 대응

4. 자동화된 모델 선택
   - 검증 정확도 기반 최고 모델 저장
   - 과적합 방지

5. 재현 가능성
   - 랜덤 시드 고정
   - 체계적인 실험 관리


[Slide 10: Challenges & Solutions]
--------------------------------------------------------------------------------
프로젝트 중 직면한 도전과 해결책입니다.

도전 1: 대용량 데이터 처리
- 문제: 101,000장의 이미지 로딩 속도
- 해결: Multi-worker DataLoader, Pin Memory 활성화

도전 2: GPU 메모리 제한
- 문제: 배치 크기 제한
- 해결: Mixed Precision Training, 최적 배치 크기 탐색

도전 3: 유사 클래스 간 혼동
- 문제: 시각적으로 유사한 음식 분류 어려움
- 해결: 데이터 증강, 전이학습을 통한 특징 학습 강화

도전 4: 과적합 위험
- 문제: 클래스당 750장으로 제한적
- 해결: Weight Decay, 데이터 증강, Learning Rate Scheduling


[Slide 11: Future Improvements]
--------------------------------------------------------------------------------
향후 개선 방향을 제시하겠습니다.

1. 모델 개선
   - 더 큰 모델 시도 (ResNet50, EfficientNet, Vision Transformer)
   - 앙상블 기법 적용
   - Test-Time Augmentation (TTA)

2. 훈련 최적화
   - 더 많은 에폭 훈련
   - Advanced Augmentation (Mixup, CutMix, AutoAugment)
   - Cosine Annealing 등 다른 스케줄러 실험

3. 성능 분석
   - 클래스별 정확도 분석
   - Confusion Matrix 생성
   - 오답 패턴 심층 분석

4. 실용화
   - 모델 경량화 (Pruning, Quantization)
   - 모바일 배포 (ONNX, TensorFlow Lite)
   - REST API 개발


[Slide 12: Conclusion]
--------------------------------------------------------------------------------
결론을 말씀드리겠습니다.

프로젝트 성과:
✓ 전이학습을 활용한 효율적인 음식 이미지 분류 시스템 개발
✓ 101개 클래스에 대한 실용적 정확도 달성
✓ 최적화된 훈련 파이프라인 구축
✓ 체계적인 실험 및 평가 프로세스 확립

주요 배운 점:
- 전이학습의 강력함
- 데이터 증강의 중요성
- 하이퍼파라미터 튜닝의 영향
- PyTorch의 효율적 활용

실용적 가치:
- 레스토랑 메뉴 자동 인식
- 음식 추천 시스템
- 식단 관리 앱
- 영양 정보 자동 제공


[Slide 13: Thank You]
--------------------------------------------------------------------------------
발표를 들어주셔서 감사합니다.

질문이 있으시면 말씀해 주세요.


================================================================================
Presentation Tips:
================================================================================

시간 배분 (총 10-12분):
- 슬라이드 1-2: 1분 (소개)
- 슬라이드 3-4: 2분 (데이터셋 & 모델)
- 슬라이드 5-6: 2분 (전처리 & 훈련 설정)
- 슬라이드 7-8: 3분 (결과 & 평가)
- 슬라이드 9-10: 2분 (기술 하이라이트 & 도전)
- 슬라이드 11-12: 2분 (향후 개선 & 결론)

발표 팁:
1. 시각 자료(그래프, 이미지)를 적극 활용
2. 기술 용어는 간단히 설명 추가
3. 핵심 수치는 강조하여 전달
4. 청중 눈높이에 맞춰 조절
5. 실습 데모가 있다면 더욱 효과적

주의사항:
- [실제 수치] 부분은 실제 훈련 결과로 채워넣기
- 시간에 맞춰 불필요한 부분은 생략
- Q&A 시간 5-10분 확보
